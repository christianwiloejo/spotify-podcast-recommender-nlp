{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7980bb65-dc96-4cb7-863e-ff449ce88ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "# sc = SparkContext() \n",
    "# sqlContext = SQLContext(sc)\n",
    "from pyspark.mllib.linalg import Vector, Vectors\n",
    "from pyspark.ml.clustering import LDA, LDAModel\n",
    "from pyspark.ml.feature import CountVectorizer , IDF\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "import re as re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d36b1d6-7ebb-4eb7-bd7c-7df65b166f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd02f461-d73e-4b2f-8891-748883b46aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/02 17:10:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"SpotifyPodcastClassification\")\\\n",
    "    .config('spark.driver.memory', '12g')\\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "221ac58d-14fc-404c-b0c7-f4ee54d4b8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cossim(v1, v2): \n",
    "    return np.dot(v1, v2) / np.sqrt(np.dot(v1, v1)) / (np.sqrt(np.dot(v2, v2))+.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d2fb636-a20d-4d3f-a833-8c0240bff952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/02 17:25:58 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , show_uri, show_name, show_description, publisher, language, rss_link, episode_uri, episode_name, episode_description, duration, show_filename_prefix, episode_filename_prefix, Unnamed: 0, episode, transcript\n",
      " Schema: _c0, show_uri, show_name, show_description, publisher, language, rss_link, episode_uri, episode_name, episode_description, duration, show_filename_prefix, episode_filename_prefix, Unnamed: 0, episode, transcript\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Volumes/GoogleDrive/My%20Drive/Documents/Columbia/CLASSES/!SEM%202%20-%20NLP/COLUMBIA%20SPOTIFY%20PODCAST/script_output/episode_transcript_data_w_metadata.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+-----------------------+----------+--------------------+--------------------+\n",
      "|_c0|            show_uri|           show_name|    show_description|           publisher| language|            rss_link|         episode_uri|        episode_name| episode_description|          duration|show_filename_prefix|episode_filename_prefix|Unnamed: 0|             episode|          transcript|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+-----------------------+----------+--------------------+--------------------+\n",
      "|  0|spotify:show:2NYt...|Kream in your Koffee|A 20-something bl...|         Katie Houle|   ['en']|https://anchor.fm...|spotify:episode:0...|1: It’s Christmas...|On the first ever...|12.700133333333332|show_2NYtxEZyYelR...|   000A9sRBYdVh66csG...|     34866|000A9sRBYdVh66csG...|Hello. Hello. Hel...|\n",
      "|  1|spotify:show:15iW...|Morning Cup Of Mu...|Ever wonder what ...|Morning Cup Of Mu...|   ['en']|https://anchor.fm...|spotify:episode:0...|The Goleta Postal...|See something, sa...| 6.019383333333334|show_15iWCbU7QoO2...|   000HP8n3hNIfglT2w...|     14162|000HP8n3hNIfglT2w...|There were two mo...|\n",
      "|  2|spotify:show:6vZR...|Inside The 18 : A...|Inside the 18 is ...|Inside the 18 GK ...|   ['en']|https://anchor.fm...|spotify:episode:0...|Ep.36 - Incorpora...|Today’s episode i...| 43.61633333333333|show_6vZRgUFTYwbA...|   001UfOruzkA3Bn1SP...|     93168|001UfOruzkA3Bn1SP...|Welcome to inside...|\n",
      "|  3|spotify:show:5BvK...|     Arrowhead Live!|Your favorite pod...|     Arrowhead Live!|['en-US']|https://anchor.fm...|spotify:episode:0...|Episode 1: Arrowh...|Join us as we tak...|           58.1892|show_5BvKEjaMSuvU...|   001i89SvIQgDuuyC5...|     69703|001i89SvIQgDuuyC5...|Hey cheese fans b...|\n",
      "|  4|spotify:show:7w3h...|               FBoL |The comedy podcas...|       Emily Edwards|   ['en']|https://www.fuckb...|spotify:episode:0...|The Lion, The Wit...|The modern morali...|          51.78205|show_7w3h3umpH74v...|   0025RWNwe2lnp6Hcn...|    104381|0025RWNwe2lnp6Hcn...|Sorry to interrup...|\n",
      "|  5|spotify:show:5ljR...|       UPSC Podcasts|Podcasts useful f...|        UPSC Podcast|   ['en']|https://anchor.fm...|spotify:episode:0...|Tourism in India ...|                  . |            13.788|show_5ljREb8VLogQ...|   0025w0gdgkl11Nzkm...|     75066|0025w0gdgkl11Nzkm...|This is all India...|\n",
      "|  6|spotify:show:3VHI...|The Feminization ...|Enter the world o...|         Kylie Gable|   ['en']|https://anchor.fm...|spotify:episode:0...|The Sissy's Mento...|Miss Jenn Davis r...|           30.5892|show_3VHIM25lUuRw...|   002NDlaaJN4vUczXH...|     50677|002NDlaaJN4vUczXH...|If you haven't he...|\n",
      "|  7|spotify:show:6fqU...|Chastity and The ...|We are four, 30 s...|            Chastity|   ['en']|https://anchor.fm...|spotify:episode:0...|Our Journey with ...|In today's episod...|39.437133333333335|show_6fqU8lOAcqQK...|   002SVJwVLa487Rmci...|     85493|002SVJwVLa487Rmci...|We are 30 somethi...|\n",
      "|  8|spotify:show:0g0g...|  They Had to Go Out|Get ready to whit...|  They Had to Go Out|   ['en']|https://anchor.fm...|spotify:episode:0...|Episode 50: Dan S...|Former Boatswain’...| 58.46978333333333|show_0g0gZz74AKcS...|   002UpWk6zCgvHSAzm...|      4311|002UpWk6zCgvHSAzm...|Get ready to whit...|\n",
      "|  9|spotify:show:1dyT...|      The Good Sign |Let’s be real and...|      Donna Simantov|   ['en']|https://anchor.fm...|spotify:episode:0...|Talia and me part...|Join us as we lea...|31.074483333333333|show_1dyTrS3vDtpC...|   003EmVD7eAmRTBSwH...|     16797|003EmVD7eAmRTBSwH...|So people are alw...|\n",
      "| 10|spotify:show:5U8m...|       Behaviorbabe |Behaviorbabe (aka...|       Behaviorbabe |   ['en']|https://anchor.fm...|spotify:episode:0...|Dr. Darlene Crone...| In this episode ...|23.543866666666663|show_5U8m0Pbd5HDB...|   003egucoR0umViUsM...|     78512|003egucoR0umViUsM...|Thanks for listen...|\n",
      "| 11|spotify:show:162G...|In the Pocket Pod...|In dance, the poc...|      Alfred Arizala|   ['en']|https://anchor.fm...|spotify:episode:0...|The Daily Flow - ...|Feel no pressure ...|12.390166666666667|show_162GxLtTwesd...|   003kQmTd3YDcR77Dj...|     14380|003kQmTd3YDcR77Dj...|So what's more en...|\n",
      "| 12|spotify:show:53Mm...|  The Willing Equine|Welcome to the of...|  The Willing Equine|   ['en']|https://anchor.fm...|spotify:episode:0...|Ep 2 // Relations...|How are relations...|23.832183333333333|show_53MmIvDLkuBw...|   003wT7YPtDMpA8r62...|     67124|003wT7YPtDMpA8r62...|Hey everyone, wel...|\n",
      "| 13|spotify:show:0hy2...|Revise - GCSE Bio...|Let other student...|Seneca Learning R...|   ['en']|https://anchor.fm...|spotify:episode:0...|GCSE Biology - Ev...|Liz looks at the ...| 4.344833333333334|show_0hy2142rv25a...|   004XIUE6xvSItQVSf...|      4688|004XIUE6xvSItQVSf...|Let's discuss wha...|\n",
      "| 14|spotify:show:3tVR...|The Pole Dance Po...|Welcome to The Po...|  Pole Dance Academy|['en-AU']|https://anchor.fm...|spotify:episode:0...| About Kira & Evgeny|You can follow Ki...|          14.72455|show_3tVReT5vxiDp...|   004Z4p2OwXM1HJ7rT...|     50176|004Z4p2OwXM1HJ7rT...|Hi and welcome ba...|\n",
      "| 15|spotify:show:65jT...| eCommerce Lifestyle|The eCommerce Lif...|         Anton Kraly|   ['en']|https://anchor.fm...|spotify:episode:0...|How Jeff Is Getti...|In this interview...|21.226666666666667|show_65jTqiesGQ9v...|   004eNUDOyWSUN3n1U...|     82430|004eNUDOyWSUN3n1U...|Everybody Anton h...|\n",
      "| 16|spotify:show:60Iu...|             MOMHOOD|Because there’s a...|Orly Shani + Bran...|   ['en']|https://anchor.fm...|spotify:episode:0...|13. How To Raise ...|Dr. Zelana Montmi...| 74.43591666666667|show_60IuLVDLnoXU...|   004scar91tc5UcMpt...|     81185|004scar91tc5UcMpt...|Welcome to Mom Ho...|\n",
      "| 17|spotify:show:5klb...|This Particular A...|Does music make y...|      Campfire Media|['en-US']|https://anchor.fm...|spotify:episode:0...|Sun Kil Moon's Gh...|Lauren Lapkus sit...| 53.68143333333333|show_5klbv9vI90U4...|   004tF9AGNDnp6eOqY...|     74606|004tF9AGNDnp6eOqY...|Hello and welcome...|\n",
      "| 18|spotify:show:0qvD...|The 3-0 Take: a D...|Too much analytic...|Dirt to Diamonds ...|   ['en']|https://anchor.fm...|spotify:episode:0...|Episode 67: Domes...|We talk circumsta...|52.066833333333335|show_0qvDMEzgA64Q...|   005RdlW93PR49TQ0C...|      9376|005RdlW93PR49TQ0C...|You're not taught...|\n",
      "| 19|spotify:show:7dsA...|        IMPACT RADIO|What does it take...|      Adella Langdon|   ['en']|https://anchor.fm...|spotify:episode:0...|              Ground|     Clear thinking | 3.619983333333333|show_7dsAofwkjFYM...|   005vkQIKPSCfFFEDh...|     98814|005vkQIKPSCfFFEDh...|I'm Adela Langdon...|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+-----------------------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.options(inferSchema='True',delimiter=',',header='True') \\\n",
    "    .csv(\"../script_output/episode_transcript_data_w_metadata.csv\")\n",
    "\n",
    "# df = df.withColumnRenamed('_c0', 'index')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e644e05-d6c9-4b64-9ed9-06d8c779bb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "|_c0|         episode_uri|    show_description|\n",
      "+---+--------------------+--------------------+\n",
      "|  0|spotify:episode:0...|A 20-something bl...|\n",
      "|  1|spotify:episode:0...|Ever wonder what ...|\n",
      "|  2|spotify:episode:0...|Inside the 18 is ...|\n",
      "|  3|spotify:episode:0...|Your favorite pod...|\n",
      "|  4|spotify:episode:0...|The comedy podcas...|\n",
      "|  5|spotify:episode:0...|Podcasts useful f...|\n",
      "|  6|spotify:episode:0...|Enter the world o...|\n",
      "|  7|spotify:episode:0...|We are four, 30 s...|\n",
      "|  8|spotify:episode:0...|Get ready to whit...|\n",
      "|  9|spotify:episode:0...|Let’s be real and...|\n",
      "| 10|spotify:episode:0...|Behaviorbabe (aka...|\n",
      "| 11|spotify:episode:0...|In dance, the poc...|\n",
      "| 12|spotify:episode:0...|Welcome to the of...|\n",
      "| 13|spotify:episode:0...|Let other student...|\n",
      "| 14|spotify:episode:0...|Welcome to The Po...|\n",
      "| 15|spotify:episode:0...|The eCommerce Lif...|\n",
      "| 16|spotify:episode:0...|Because there’s a...|\n",
      "| 17|spotify:episode:0...|Does music make y...|\n",
      "| 18|spotify:episode:0...|Too much analytic...|\n",
      "| 19|spotify:episode:0...|What does it take...|\n",
      "+---+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/02 17:25:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , show_description, episode_uri\n",
      " Schema: _c0, show_description, episode_uri\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Volumes/GoogleDrive/My%20Drive/Documents/Columbia/CLASSES/!SEM%202%20-%20NLP/COLUMBIA%20SPOTIFY%20PODCAST/script_output/episode_transcript_data_w_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "df_clean = df.select('_c0', 'episode_uri', 'show_description')\n",
    "df_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd00331c-f04c-4021-81fa-494a7f32d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = df_clean.rdd.map(lambda x : x['show_description']).filter(lambda x: x is not None)\n",
    "StopWords = stopwords.words(\"english\")\n",
    "lmtzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe1d687d-6466-4bd0-84fa-9aa587e798b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/02 17:26:10 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , show_description, episode_uri\n",
      " Schema: _c0, show_description, episode_uri\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Volumes/GoogleDrive/My%20Drive/Documents/Columbia/CLASSES/!SEM%202%20-%20NLP/COLUMBIA%20SPOTIFY%20PODCAST/script_output/episode_transcript_data_w_metadata.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tokens = transcript.map( lambda document: document.strip().lower())               \\\n",
    "    .map( lambda document: re.split(\" \", document))          \\\n",
    "    .map( lambda word: [x for x in word if x.isalpha()])           \\\n",
    "    .map( lambda word: [x for x in word if len(x) > 3] )           \\\n",
    "    .map( lambda word: [x for x in word if x not in StopWords])    \\\n",
    "    .map( lambda word: [x for x in word if x not in ['welcome', 'episode', 'hello']])    \\\n",
    "    .map( lambda word: [lmtzr.lemmatize(x,'v') for x in word]) \\\n",
    "    .zipWithIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "723504bb-a880-4e7d-ba78-bb1157a37ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/02 17:26:20 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , show_description, episode_uri\n",
      " Schema: _c0, show_description, episode_uri\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Volumes/GoogleDrive/My%20Drive/Documents/Columbia/CLASSES/!SEM%202%20-%20NLP/COLUMBIA%20SPOTIFY%20PODCAST/script_output/episode_transcript_data_w_metadata.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|       list_of_words|index|\n",
      "+--------------------+-----+\n",
      "|[blunt, female, t...|    0|\n",
      "|[ever, wonder, mu...|    1|\n",
      "|[inside, source, ...|    2|\n",
      "|[favorite, podcas...|    3|\n",
      "|[comedy, podcast,...|    4|\n",
      "|[podcast, useful,...|    5|\n",
      "|[enter, world, do...|    6|\n",
      "|[somethings, live...|    7|\n",
      "|[ready, whiten, k...|    8|\n",
      "|[real, life, chal...|    9|\n",
      "|[behaviorbabe, am...|   10|\n",
      "|[pocket, place, m...|   11|\n",
      "|[official, will, ...|   12|\n",
      "|[students, help, ...|   13|\n",
      "|[pole, dance, tal...|   14|\n",
      "|[ecommerce, lifes...|   15|\n",
      "|[million, ways, c...|   16|\n",
      "|[music, make, fee...|   17|\n",
      "|[much, enough, ta...|   18|\n",
      "|[take, powerful, ...|   19|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/02 17:26:20 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , show_description, episode_uri\n",
      " Schema: _c0, show_description, episode_uri\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Volumes/GoogleDrive/My%20Drive/Documents/Columbia/CLASSES/!SEM%202%20-%20NLP/COLUMBIA%20SPOTIFY%20PODCAST/script_output/episode_transcript_data_w_metadata.csv\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/christianwiloejo/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 186, in manager\n",
      "  File \"/Users/christianwiloejo/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 74, in worker\n",
      "  File \"/Users/christianwiloejo/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 643, in main\n",
      "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
      "  File \"/Users/christianwiloejo/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    }
   ],
   "source": [
    "df_txts = spark.createDataFrame(tokens, [\"list_of_words\",'index'])\n",
    "df_txts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0039ba00-0b23-49d7-87ad-8a383fef671b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|       list_of_words|index|   tokens_sw_removed|\n",
      "+--------------------+-----+--------------------+\n",
      "|[blunt, female, t...|    0|[blunt, female, t...|\n",
      "|[ever, wonder, mu...|    1|[ever, wonder, mu...|\n",
      "|[inside, source, ...|    2|[inside, source, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/02 17:26:20 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , show_description, episode_uri\n",
      " Schema: _c0, show_description, episode_uri\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Volumes/GoogleDrive/My%20Drive/Documents/Columbia/CLASSES/!SEM%202%20-%20NLP/COLUMBIA%20SPOTIFY%20PODCAST/script_output/episode_transcript_data_w_metadata.csv\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/christianwiloejo/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 186, in manager\n",
      "  File \"/Users/christianwiloejo/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 74, in worker\n",
      "  File \"/Users/christianwiloejo/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 643, in main\n",
      "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
      "  File \"/Users/christianwiloejo/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    }
   ],
   "source": [
    "stopwrmv = StopWordsRemover(inputCol = 'list_of_words', outputCol = 'tokens_sw_removed')\n",
    "\n",
    "df_txts = stopwrmv.transform(df_txts)\n",
    "df_txts.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0215b65a-2e41-4d98-88a9-53dae65809dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/02 17:26:21 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , show_description, episode_uri\n",
      " Schema: _c0, show_description, episode_uri\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Volumes/GoogleDrive/My%20Drive/Documents/Columbia/CLASSES/!SEM%202%20-%20NLP/COLUMBIA%20SPOTIFY%20PODCAST/script_output/episode_transcript_data_w_metadata.csv\n",
      "21/12/02 17:26:31 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , show_description, episode_uri\n",
      " Schema: _c0, show_description, episode_uri\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Volumes/GoogleDrive/My%20Drive/Documents/Columbia/CLASSES/!SEM%202%20-%20NLP/COLUMBIA%20SPOTIFY%20PODCAST/script_output/episode_transcript_data_w_metadata.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+\n",
      "|       list_of_words|index|   tokens_sw_removed|        raw_features|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "|[blunt, female, t...|    0|[blunt, female, t...|(5000,[20,26,31,6...|\n",
      "|[ever, wonder, mu...|    1|[ever, wonder, mu...|(5000,[1,20,22,66...|\n",
      "|[inside, source, ...|    2|[inside, source, ...|(5000,[6,9,14,23,...|\n",
      "|[favorite, podcas...|    3|[favorite, podcas...|(5000,[0,33,52,70...|\n",
      "|[comedy, podcast,...|    4|[comedy, podcast,...|(5000,[0,1,5,9,11...|\n",
      "|[podcast, useful,...|    5|[podcast, useful,...|(5000,[0,88,261,8...|\n",
      "|[enter, world, do...|    6|[enter, world, do...|(5000,[1,5,10,26,...|\n",
      "|[somethings, live...|    7|[somethings, live...|(5000,[6,17,232,5...|\n",
      "|[ready, whiten, k...|    8|[ready, whiten, k...|(5000,[1,2,10,39,...|\n",
      "|[real, life, chal...|    9|[real, life, chal...|(5000,[0,7,8,9,16...|\n",
      "|[behaviorbabe, am...|   10|[behaviorbabe, am...|(5000,[0,51,96,13...|\n",
      "|[pocket, place, m...|   11|[pocket, place, m...|(5000,[0,18,21,58...|\n",
      "|[official, will, ...|   12|[official, equine...|(5000,[0,1,50,119...|\n",
      "|[students, help, ...|   13|[students, help, ...|(5000,[3,18,44,67...|\n",
      "|[pole, dance, tal...|   14|[pole, dance, tal...|(5000,[0,2,11,14,...|\n",
      "|[ecommerce, lifes...|   15|[ecommerce, lifes...|(5000,[0,9,18,45,...|\n",
      "|[million, ways, c...|   16|[million, ways, c...|(5000,[0,32,48,54...|\n",
      "|[music, make, fee...|   17|[music, make, fee...|(5000,[0,3,5,8,9,...|\n",
      "|[much, enough, ta...|   18|[much, enough, ta...|(5000,[5,19,20,25...|\n",
      "|[take, powerful, ...|   19|[take, powerful, ...|(5000,[20,612,422...|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/christianwiloejo/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 186, in manager\n",
      "  File \"/Users/christianwiloejo/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 74, in worker\n",
      "  File \"/Users/christianwiloejo/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 643, in main\n",
      "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
      "  File \"/Users/christianwiloejo/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    }
   ],
   "source": [
    "# TF\n",
    "cv = CountVectorizer(inputCol=\"list_of_words\", outputCol=\"raw_features\", vocabSize=5000, minDF=10.0)\n",
    "cvmodel = cv.fit(df_txts)\n",
    "result_cv = cvmodel.transform(df_txts)\n",
    "result_cv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "195b3761-f7c5-4c60-a81b-d8f190821a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/02 17:26:31 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , show_description, episode_uri\n",
      " Schema: _c0, show_description, episode_uri\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Volumes/GoogleDrive/My%20Drive/Documents/Columbia/CLASSES/!SEM%202%20-%20NLP/COLUMBIA%20SPOTIFY%20PODCAST/script_output/episode_transcript_data_w_metadata.csv\n",
      "21/12/02 17:26:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , show_description, episode_uri\n",
      " Schema: _c0, show_description, episode_uri\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Volumes/GoogleDrive/My%20Drive/Documents/Columbia/CLASSES/!SEM%202%20-%20NLP/COLUMBIA%20SPOTIFY%20PODCAST/script_output/episode_transcript_data_w_metadata.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|       list_of_words|index|   tokens_sw_removed|        raw_features|            features|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|[blunt, female, t...|    0|[blunt, female, t...|(5000,[20,26,31,6...|(5000,[20,26,31,6...|\n",
      "|[ever, wonder, mu...|    1|[ever, wonder, mu...|(5000,[1,20,22,66...|(5000,[1,20,22,66...|\n",
      "|[inside, source, ...|    2|[inside, source, ...|(5000,[6,9,14,23,...|(5000,[6,9,14,23,...|\n",
      "|[favorite, podcas...|    3|[favorite, podcas...|(5000,[0,33,52,70...|(5000,[0,33,52,70...|\n",
      "|[comedy, podcast,...|    4|[comedy, podcast,...|(5000,[0,1,5,9,11...|(5000,[0,1,5,9,11...|\n",
      "|[podcast, useful,...|    5|[podcast, useful,...|(5000,[0,88,261,8...|(5000,[0,88,261,8...|\n",
      "|[enter, world, do...|    6|[enter, world, do...|(5000,[1,5,10,26,...|(5000,[1,5,10,26,...|\n",
      "|[somethings, live...|    7|[somethings, live...|(5000,[6,17,232,5...|(5000,[6,17,232,5...|\n",
      "|[ready, whiten, k...|    8|[ready, whiten, k...|(5000,[1,2,10,39,...|(5000,[1,2,10,39,...|\n",
      "|[real, life, chal...|    9|[real, life, chal...|(5000,[0,7,8,9,16...|(5000,[0,7,8,9,16...|\n",
      "|[behaviorbabe, am...|   10|[behaviorbabe, am...|(5000,[0,51,96,13...|(5000,[0,51,96,13...|\n",
      "|[pocket, place, m...|   11|[pocket, place, m...|(5000,[0,18,21,58...|(5000,[0,18,21,58...|\n",
      "|[official, will, ...|   12|[official, equine...|(5000,[0,1,50,119...|(5000,[0,1,50,119...|\n",
      "|[students, help, ...|   13|[students, help, ...|(5000,[3,18,44,67...|(5000,[3,18,44,67...|\n",
      "|[pole, dance, tal...|   14|[pole, dance, tal...|(5000,[0,2,11,14,...|(5000,[0,2,11,14,...|\n",
      "|[ecommerce, lifes...|   15|[ecommerce, lifes...|(5000,[0,9,18,45,...|(5000,[0,9,18,45,...|\n",
      "|[million, ways, c...|   16|[million, ways, c...|(5000,[0,32,48,54...|(5000,[0,32,48,54...|\n",
      "|[music, make, fee...|   17|[music, make, fee...|(5000,[0,3,5,8,9,...|(5000,[0,3,5,8,9,...|\n",
      "|[much, enough, ta...|   18|[much, enough, ta...|(5000,[5,19,20,25...|(5000,[5,19,20,25...|\n",
      "|[take, powerful, ...|   19|[take, powerful, ...|(5000,[20,612,422...|(5000,[20,612,422...|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/christianwiloejo/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 186, in manager\n",
      "  File \"/Users/christianwiloejo/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 74, in worker\n",
      "  File \"/Users/christianwiloejo/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 643, in main\n",
      "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
      "  File \"/Users/christianwiloejo/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    }
   ],
   "source": [
    "# IDF\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "idfModel = idf.fit(result_cv)\n",
    "result_tfidf = idfModel.transform(result_cv) \n",
    "result_tfidf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d97ffe-3e6e-48ae-aacd-56620d14cda6",
   "metadata": {},
   "source": [
    "# Fit and Describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7e8ca60-ef12-48e0-afe6-fd486697bdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/02 17:26:42 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , show_description, episode_uri\n",
      " Schema: _c0, show_description, episode_uri\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Volumes/GoogleDrive/My%20Drive/Documents/Columbia/CLASSES/!SEM%202%20-%20NLP/COLUMBIA%20SPOTIFY%20PODCAST/script_output/episode_transcript_data_w_metadata.csv\n",
      "21/12/02 17:26:54 WARN DAGScheduler: Broadcasting large task binary with size 1373.2 KiB\n",
      "21/12/02 17:26:54 WARN DAGScheduler: Broadcasting large task binary with size 1373.2 KiB\n",
      "21/12/02 17:26:55 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , show_description, episode_uri\n",
      " Schema: _c0, show_description, episode_uri\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Volumes/GoogleDrive/My%20Drive/Documents/Columbia/CLASSES/!SEM%202%20-%20NLP/COLUMBIA%20SPOTIFY%20PODCAST/script_output/episode_transcript_data_w_metadata.csv\n",
      "21/12/02 17:33:42 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: index, show_description, episode_uri\n",
      " Schema: _c0, show_description, episode_uri\n",
      "Expected: _c0 but found: index\n",
      "CSV file: file:///Volumes/GoogleDrive/My%20Drive/Documents/Columbia/CLASSES/!SEM%202%20-%20NLP/COLUMBIA%20SPOTIFY%20PODCAST/script_output/episode_transcript_data_w_metadata.csv\n",
      "21/12/02 17:33:49 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: index, show_description, episode_uri\n",
      " Schema: _c0, show_description, episode_uri\n",
      "Expected: _c0 but found: index\n",
      "CSV file: file:///Volumes/GoogleDrive/My%20Drive/Documents/Columbia/CLASSES/!SEM%202%20-%20NLP/COLUMBIA%20SPOTIFY%20PODCAST/script_output/episode_transcript_data_w_metadata.csv\n",
      "[Stage 96:=====================================================>  (24 + 1) / 25]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lower bound on the log likelihood of the entire corpus: -58399722.72354713\n",
      "The upper bound on perplexity: 7.1869648110218005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lda = LDA(k=10, maxIter = 2)\n",
    "model = lda.fit(result_tfidf.select('index', 'features'))\n",
    "ll = model.logLikelihood(result_tfidf)\n",
    "lp = model.logPerplexity(result_tfidf)\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "print(\"The upper bound on perplexity: \" + str(lp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08cb3631-3187-4ce1-8fc9-f2242856d133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+--------------------+--------------------+\n",
      "|topic|         termIndices|         termWeights|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|[0, 16, 13, 3, 25...|[0.00611678902606...|\n",
      "|    1|[10, 0, 8, 1, 17,...|[0.00685969000664...|\n",
      "|    2|[2, 0, 4, 57, 5, ...|[0.00674179527515...|\n",
      "|    3|[65, 260, 0, 55, ...|[0.00890301497464...|\n",
      "|    4|[2, 178, 13, 8, 4...|[0.00558137219786...|\n",
      "|    5|[13, 1, 61, 0, 17...|[0.00576652204050...|\n",
      "|    6|[104, 3, 139, 285...|[0.00940090967704...|\n",
      "|    7|[374, 7, 20, 0, 1...|[0.00855893723711...|\n",
      "|    8|[145, 102, 154, 3...|[0.00858467743446...|\n",
      "|    9|[82, 89, 153, 24,...|[0.01574083654863...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe topics.\n",
    "topics = model.describeTopics(7)\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "042af7eb-21c3-435b-acb4-6fee2cb9df29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic cluster:  0\n",
      "podcast\n",
      "people\n",
      "best\n",
      "help\n",
      "asmr\n",
      "support\n",
      "unsolved\n",
      "Topic cluster:  1\n",
      "stories\n",
      "podcast\n",
      "make\n",
      "support\n",
      "live\n",
      "jeremy\n",
      "life\n",
      "Topic cluster:  2\n",
      "talk\n",
      "podcast\n",
      "every\n",
      "media\n",
      "host\n",
      "stories\n",
      "life\n",
      "Topic cluster:  3\n",
      "english\n",
      "craig\n",
      "podcast\n",
      "teach\n",
      "break\n",
      "want\n",
      "show\n",
      "Topic cluster:  4\n",
      "talk\n",
      "black\n",
      "best\n",
      "make\n",
      "every\n",
      "podcast\n",
      "culture\n",
      "Topic cluster:  5\n",
      "best\n",
      "support\n",
      "think\n",
      "podcast\n",
      "live\n",
      "read\n",
      "daily\n",
      "Topic cluster:  6\n",
      "students\n",
      "help\n",
      "brand\n",
      "nintendo\n",
      "personal\n",
      "gary\n",
      "support\n"
     ]
    }
   ],
   "source": [
    "num_words = 20\n",
    "num_topics = 7\n",
    "# topicIndices = sc.parallelize(model.describeTopics(maxTermsPerTopic = num_words))\n",
    "topic_list = topics.collect()\n",
    "for i in range(0,num_topics):\n",
    "    print(\"Topic cluster: \", i)\n",
    "    for index in topic_list[i][1]:\n",
    "        print(cvmodel.vocabulary[index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee342415-7916-4a2f-8c6f-e9943d67400c",
   "metadata": {},
   "source": [
    "1. Iterate through until we get meaningful results\n",
    "2. Evaluation: Manually annotating - then that's our eval metric  --> give clients to think about - perhaps \n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7d3e6aa-9778-4dc2-b8df-7548f4c36e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic cluster:  0\n",
      "happen\n",
      "go\n",
      "whole\n",
      "things\n",
      "anything\n",
      "something\n",
      "like\n",
      "Topic cluster:  1\n",
      "think\n",
      "follow\n",
      "everything\n",
      "anything\n",
      "every\n",
      "life\n",
      "live\n",
      "Topic cluster:  2\n",
      "next\n",
      "good\n",
      "break\n",
      "care\n",
      "nothing\n",
      "back\n",
      "would\n",
      "Topic cluster:  3\n",
      "many\n",
      "understand\n",
      "stuff\n",
      "leave\n",
      "would\n",
      "mean\n",
      "still\n",
      "Topic cluster:  4\n",
      "say\n",
      "actually\n",
      "still\n",
      "person\n",
      "happen\n",
      "okay\n",
      "hold\n",
      "Topic cluster:  5\n",
      "feel\n",
      "make\n",
      "take\n",
      "say\n",
      "person\n",
      "best\n",
      "able\n",
      "Topic cluster:  6\n",
      "really\n",
      "work\n",
      "break\n",
      "actually\n",
      "think\n",
      "talk\n",
      "whole\n"
     ]
    }
   ],
   "source": [
    "num_words = 20\n",
    "num_topics = 7\n",
    "# topicIndices = sc.parallelize(model.describeTopics(maxTermsPerTopic = num_words))\n",
    "topic_list = topics.collect()\n",
    "for i in range(0,num_topics):\n",
    "    print(\"Topic cluster: \", i)\n",
    "    for index in topic_list[i][1]:\n",
    "        print(cvmodel.vocabulary[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9a0f4d-8126-4b99-81be-4e47480b951c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
